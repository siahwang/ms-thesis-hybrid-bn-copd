{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07865d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# 5-Fold Nested CV Pipeline for ADASYN + Logistic Regression Experiment\n",
    "#\n",
    "# - Outer 5-fold: Evaluates generalization performance (Main metrics: Recall/F1/AUC)\n",
    "# - Inner 5-fold: Selects ADASYN (r, k) hyperparameters (using *only* the train set)\n",
    "# =========================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, roc_auc_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e649837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (2776, 11)\n",
      "                ID  COPD  age     sex OccupationRisk Income         smoking  \\\n",
      "0  CODA24L27862226     0  50s    Male    Non–at-risk   High   Former Smoker   \n",
      "1  CODA24L31534447     0  50s    Male        At-risk   High  Current Smoker   \n",
      "2  CODA24L47263638     0  50s    Male    Non–at-risk    Low      Non-smoker   \n",
      "3  CODA24L14080640     0  50s  Female    Non–at-risk   High      Non-smoker   \n",
      "4  CODA24L76507177     1  50s    Male    Non–at-risk   High   Former Smoker   \n",
      "\n",
      "  Packyears Asthma BMI_Group PM25_Group  \n",
      "0       low     No     Obese       high  \n",
      "1       low     No    Normal        low  \n",
      "2       NaN     No     Obese       high  \n",
      "3       NaN     No    Normal       high  \n",
      "4       low     No    Normal        low  \n",
      "Shape after one-hot encoding: (2776, 24)\n",
      "   age_50s  age_60s  age_70+  sex_Female  sex_Male  OccupationRisk_At-risk  \\\n",
      "0     True    False    False       False      True                   False   \n",
      "1     True    False    False       False      True                    True   \n",
      "2     True    False    False       False      True                   False   \n",
      "3     True    False    False        True     False                   False   \n",
      "4     True    False    False       False      True                   False   \n",
      "\n",
      "   OccupationRisk_Non–at-risk  OccupationRisk_nan  Income_High  Income_Low  \\\n",
      "0                        True               False         True       False   \n",
      "1                       False               False         True       False   \n",
      "2                        True               False        False        True   \n",
      "3                        True               False         True       False   \n",
      "4                        True               False         True       False   \n",
      "\n",
      "   ...  Packyears_high  Packyears_low  Packyears_nan  Asthma_No  Asthma_Yes  \\\n",
      "0  ...           False           True          False       True       False   \n",
      "1  ...           False           True          False       True       False   \n",
      "2  ...           False          False           True       True       False   \n",
      "3  ...           False          False           True       True       False   \n",
      "4  ...           False           True          False       True       False   \n",
      "\n",
      "   BMI_Group_Normal  BMI_Group_Obese  BMI_Group_nan  PM25_Group_high  \\\n",
      "0             False             True          False             True   \n",
      "1              True            False          False            False   \n",
      "2             False             True          False             True   \n",
      "3              True            False          False             True   \n",
      "4              True            False          False            False   \n",
      "\n",
      "   PM25_Group_low  \n",
      "0           False  \n",
      "1            True  \n",
      "2           False  \n",
      "3           False  \n",
      "4            True  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 0. Load Data & Preprocessing (up to One-Hot Encoding)\n",
    "# ------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(\"/Users/hwangsia/final_data.csv\")\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "y_all = df[\"COPD\"]\n",
    "X_raw = df.drop(columns=[\"COPD\", \"ID\"])  # Remove unnecessary identifiers\n",
    "\n",
    "# Store original feature names for later categorical decoding\n",
    "orig_feature_names = list(X_raw.columns)\n",
    "\n",
    "# Treat all features as categorical and convert to string (for one-hot consistency)\n",
    "X_raw = X_raw.astype(str)\n",
    "\n",
    "# One-hot encoding (drop_first=False keeps all levels -> allows decoding later)\n",
    "X_encoded = pd.get_dummies(X_raw, drop_first=False)\n",
    "\n",
    "print(\"Shape after one-hot encoding:\", X_encoded.shape)\n",
    "print(X_encoded.head())\n",
    "\n",
    "# Map original variables -> corresponding dummy columns (for decoding)\n",
    "dummy_map = {\n",
    "    var: [c for c in X_encoded.columns if c.startswith(var + \"_\")]\n",
    "    for var in orig_feature_names\n",
    "}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Define ADASYN Hyperparameter Grid\n",
    "#    (sampling_strategy=r, n_neighbors=k)\n",
    "# ------------------------------------------------\n",
    "\n",
    "r_values = [round(v, 2) for v in np.arange(0.20, 1.01, 0.10)]  # 0.20, 0.30, ..., 1.00\n",
    "k_values = [3, 5, 7, 9, 11, 13, 15]                        # Candidate k-neighbor values\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Outer StratifiedKFold (5-fold)\n",
    "#    These are the folds for final reporting.\n",
    "# ------------------------------------------------\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# For storing results\n",
    "fold_results = []  # Record performance for each fold\n",
    "adasyn_train_decoded = {}  # Store decoded oversampled train set per fold\n",
    "adasyn_test_decoded = {}   # Store decoded original test set per fold\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper Function: Decode one-hot (or scaled) data back to categorical labels\n",
    "# - row: A single pd.Series (one sample)\n",
    "# - dummy_map: {orig_var: [var_level1, var_level2, ...]}\n",
    "# ------------------------------------------------\n",
    "def decode_row(row_series, dummy_map):\n",
    "    rec = {}\n",
    "    for var, cols_for_var in dummy_map.items():\n",
    "        vals = row_series[cols_for_var].values.astype(float)\n",
    "        winner_idx = int(np.argmax(vals))\n",
    "        winner_col = cols_for_var[winner_idx]\n",
    "        # e.g., \"Smoking_Current\" -> \"Current\"\n",
    "        level_name = winner_col.split(var + \"_\", 1)[1]\n",
    "        rec[var] = level_name\n",
    "    return rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f40d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== [FOLD 1] ==========\n",
      "[FOLD 1] Selected ADASYN (r, k): (1.0, 13)\n",
      "[FOLD 1] orig_recall=0.014, aug_recall=0.739\n",
      "[FOLD 1] orig_f1=0.028, aug_f1=0.336\n",
      "[FOLD 1] orig_auc=0.750, aug_auc=0.729\n",
      "\n",
      "========== [FOLD 2] ==========\n",
      "[FOLD 2] Selected ADASYN (r, k): (1.0, 7)\n",
      "[FOLD 2] orig_recall=0.015, aug_recall=0.721\n",
      "[FOLD 2] orig_f1=0.029, aug_f1=0.339\n",
      "[FOLD 2] orig_auc=0.734, aug_auc=0.732\n",
      "\n",
      "========== [FOLD 3] ==========\n",
      "[FOLD 3] Selected ADASYN (r, k): (1.0, 3)\n",
      "[FOLD 3] orig_recall=0.059, aug_recall=0.618\n",
      "[FOLD 3] orig_f1=0.104, aug_f1=0.311\n",
      "[FOLD 3] orig_auc=0.708, aug_auc=0.706\n",
      "\n",
      "========== [FOLD 4] ==========\n",
      "[FOLD 4] Selected ADASYN (r, k): (1.0, 3)\n",
      "[FOLD 4] orig_recall=0.015, aug_recall=0.603\n",
      "[FOLD 4] orig_f1=0.028, aug_f1=0.293\n",
      "[FOLD 4] orig_auc=0.676, aug_auc=0.669\n",
      "\n",
      "========== [FOLD 5] ==========\n",
      "[FOLD 5] Selected ADASYN (r, k): (1.0, 7)\n",
      "[FOLD 5] orig_recall=0.043, aug_recall=0.725\n",
      "[FOLD 5] orig_f1=0.083, aug_f1=0.355\n",
      "[FOLD 5] orig_auc=0.752, aug_auc=0.757\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# Start Outer CV Loop\n",
    "# ------------------------------------------------\n",
    "\n",
    "for fold_id, (train_idx, test_idx) in enumerate(outer_cv.split(X_encoded, y_all), start=1):\n",
    "    print(f\"\\n========== [FOLD {fold_id}] ==========\")\n",
    "\n",
    "    X_tr_full = X_encoded.iloc[train_idx].copy()\n",
    "    y_tr_full = y_all.iloc[train_idx].copy()\n",
    "    X_te_full = X_encoded.iloc[test_idx].copy()\n",
    "    y_te_full = y_all.iloc[test_idx].copy()\n",
    "\n",
    "    # =========================================\n",
    "    # (A) Inner 5-fold CV to select ADASYN (r, k)\n",
    "    #     -> This uses *only* the outer-train set (X_tr_full, y_tr_full)\n",
    "    # =========================================\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    grid_records = []  # Summary of (r,k) performance within this outer fold\n",
    "\n",
    "    for r in r_values:\n",
    "        for k in k_values:\n",
    "\n",
    "            cv_recalls = []\n",
    "            cv_f1s = []\n",
    "\n",
    "            # Inner 5-fold: (outer-train -> inner-train / inner-val)\n",
    "            for inner_tr_idx, inner_val_idx in inner_cv.split(X_tr_full, y_tr_full):\n",
    "                X_inner_tr = X_tr_full.iloc[inner_tr_idx].copy()\n",
    "                y_inner_tr = y_tr_full.iloc[inner_tr_idx].copy()\n",
    "                X_inner_val = X_tr_full.iloc[inner_val_idx].copy()\n",
    "                y_inner_val = y_tr_full.iloc[inner_val_idx].copy()\n",
    "\n",
    "                # Scaler is fit *only* on inner-train\n",
    "                scaler_inner = StandardScaler()\n",
    "                X_inner_tr_scaled = scaler_inner.fit_transform(X_inner_tr)\n",
    "                X_inner_val_scaled = scaler_inner.transform(X_inner_val)\n",
    "\n",
    "                # Oversample *only* the inner-train set with ADASYN\n",
    "                ada = ADASYN(\n",
    "                    sampling_strategy=r,\n",
    "                    n_neighbors=k,\n",
    "                    random_state=RANDOM_STATE\n",
    "                )\n",
    "\n",
    "                try:\n",
    "                    X_inner_tr_aug, y_inner_tr_aug = ada.fit_resample(\n",
    "                        X_inner_tr_scaled, y_inner_tr\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    # ADASYN might fail with extreme r/k settings (e.g., k > minority samples)\n",
    "                    # If it fails, just skip this combination\n",
    "                    continue\n",
    "\n",
    "                # Train Logistic Regression\n",
    "                clf_inner = LogisticRegression(\n",
    "                    random_state=RANDOM_STATE,\n",
    "                    max_iter=1000\n",
    "                )\n",
    "                clf_inner.fit(X_inner_tr_aug, y_inner_tr_aug)\n",
    "\n",
    "                # Predict on inner-val (using default 0.5 threshold)\n",
    "                y_inner_val_pred = clf_inner.predict(X_inner_val_scaled)\n",
    "\n",
    "                cv_recalls.append(recall_score(y_inner_val, y_inner_val_pred))\n",
    "                cv_f1s.append(f1_score(y_inner_val, y_inner_val_pred))\n",
    "\n",
    "            if len(cv_recalls) == 0:\n",
    "                # If this (r,k) combo failed all inner folds, skip it\n",
    "                continue\n",
    "\n",
    "            mean_rec = float(np.mean(cv_recalls))\n",
    "            std_rec = float(np.std(cv_recalls, ddof=1))\n",
    "            mean_f1 = float(np.mean(cv_f1s))\n",
    "            std_f1  = float(np.std(cv_f1s, ddof=1))\n",
    "\n",
    "            grid_records.append({\n",
    "                \"r\": r,\n",
    "                \"k\": k,\n",
    "                \"mean_recall\": mean_rec,\n",
    "                \"std_recall\": std_rec,\n",
    "                \"mean_f1\": mean_f1,\n",
    "                \"std_f1\": std_f1\n",
    "            })\n",
    "\n",
    "    grid_df = pd.DataFrame(grid_records)\n",
    "\n",
    "    # If grid_df is empty (all ADASYN combos failed), we must use a fallback.\n",
    "    if grid_df.empty:\n",
    "        print(\"WARNING: ADASYN grid search failed for this fold. Using fallback (r=1.0, k=3).\")\n",
    "        best_r, best_k = 1.0, 3\n",
    "    else:\n",
    "        # Select best: 1st by highest mean_recall, 2nd by lowest std_recall (tie-breaker)\n",
    "        grid_df_sorted = grid_df.sort_values(\n",
    "            by=[\"mean_recall\", \"std_recall\"],\n",
    "            ascending=[False, True]\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        best_r = float(grid_df_sorted.loc[0, \"r\"])\n",
    "        best_k = int(grid_df_sorted.loc[0, \"k\"])\n",
    "\n",
    "    print(f\"[FOLD {fold_id}] Selected ADASYN (r, k): ({best_r}, {best_k})\")\n",
    "\n",
    "    # =========================================\n",
    "    # (B) Final Scaling & ADASYN Application (on the *entire* outer-train set)\n",
    "    # =========================================\n",
    "\n",
    "    scaler_full = StandardScaler()\n",
    "    X_tr_scaled_full = scaler_full.fit_transform(X_tr_full)\n",
    "    X_te_scaled_full = scaler_full.transform(X_te_full)\n",
    "\n",
    "    # Model 1: Trained on the original, imbalanced train set (Baseline)\n",
    "    clf_orig = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    clf_orig.fit(X_tr_scaled_full, y_tr_full)\n",
    "\n",
    "    # Model 2: Trained on the ADASYN-oversampled train set\n",
    "    ada_best = ADASYN(\n",
    "        sampling_strategy=best_r,\n",
    "        n_neighbors=best_k,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        X_tr_aug, y_tr_aug = ada_best.fit_resample(X_tr_scaled_full, y_tr_full)\n",
    "    except Exception as e:\n",
    "        # Fallback in case the chosen params fail on the full outer-train\n",
    "        print(f\"[FOLD {fold_id}] WARNING: ADASYN failed with chosen params, using fallback r=1.0,k=3\")\n",
    "        ada_best = ADASYN(\n",
    "            sampling_strategy=1.0,\n",
    "            n_neighbors=3,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        X_tr_aug, y_tr_aug = ada_best.fit_resample(X_tr_scaled_full, y_tr_full)\n",
    "\n",
    "    clf_aug = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    clf_aug.fit(X_tr_aug, y_tr_aug)\n",
    "\n",
    "    # =========================================\n",
    "    # (C) Evaluate performance on this fold's test set (outer-test)\n",
    "    #     (The test set is *never* oversampled)\n",
    "    # =========================================\n",
    "\n",
    "    # (1) Model trained on original imbalanced data (Baseline)\n",
    "    y_pred_orig = clf_orig.predict(X_te_scaled_full)\n",
    "    y_prob_orig = clf_orig.predict_proba(X_te_scaled_full)[:, 1]\n",
    "\n",
    "    orig_recall = recall_score(y_te_full, y_pred_orig)\n",
    "    orig_f1     = f1_score(y_te_full, y_pred_orig)\n",
    "    orig_prec   = precision_score(y_te_full, y_pred_orig, zero_division=0)\n",
    "    orig_auc    = roc_auc_score(y_te_full, y_prob_orig)\n",
    "\n",
    "    # (2) Model trained on ADASYN-augmented data\n",
    "    y_pred_aug = clf_aug.predict(X_te_scaled_full)\n",
    "    y_prob_aug = clf_aug.predict_proba(X_te_scaled_full)[:, 1]\n",
    "\n",
    "    aug_recall = recall_score(y_te_full, y_pred_aug)\n",
    "    aug_f1     = f1_score(y_te_full, y_pred_aug)\n",
    "    aug_prec   = precision_score(y_te_full, y_pred_aug, zero_division=0)\n",
    "    aug_auc    = roc_auc_score(y_te_full, y_prob_aug)\n",
    "\n",
    "    # Store per-fold summary\n",
    "    fold_results.append({\n",
    "        \"fold\": fold_id,\n",
    "        \"adasyn_r\": best_r,\n",
    "        \"adasyn_k\": best_k,\n",
    "\n",
    "        \"orig_recall\": orig_recall,\n",
    "        \"orig_precision\": orig_prec,\n",
    "        \"orig_f1\": orig_f1,\n",
    "        \"orig_auc\": orig_auc,\n",
    "\n",
    "        \"aug_recall\": aug_recall,\n",
    "        \"aug_precision\": aug_prec,\n",
    "        \"aug_f1\": aug_f1,\n",
    "        \"aug_auc\": aug_auc\n",
    "    })\n",
    "\n",
    "    print(f\"[FOLD {fold_id}] orig_recall={orig_recall:.3f}, aug_recall={aug_recall:.3f}\")\n",
    "    print(f\"[FOLD {fold_id}] orig_f1={orig_f1:.3f}, aug_f1={aug_f1:.3f}\")\n",
    "    print(f\"[FOLD {fold_id}] orig_auc={orig_auc:.3f}, aug_auc={aug_auc:.3f}\")\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # (D) Decode the oversampled train / original test data back into categorical format\n",
    "    # ----------------------------------------------------------------------------------\n",
    "\n",
    "    # 1) Oversampled train (X_tr_aug) is in the scaled continuous space.\n",
    "    #    -> Use inverse_transform to revert it back to the \"original one-hot space\" (approx).\n",
    "    #    This step is crucial for accurate categorical decoding (quantization).\n",
    "    X_tr_aug_unscaled = scaler_full.inverse_transform(X_tr_aug)\n",
    "\n",
    "    X_tr_aug_df = pd.DataFrame(\n",
    "        X_tr_aug_unscaled,\n",
    "        columns=X_tr_full.columns\n",
    "    )\n",
    "    y_tr_aug_series = pd.Series(y_tr_aug, name=\"COPD\")\n",
    "\n",
    "    # 2) Decode the oversampled train set (select category using argmax of the dummy group)\n",
    "    decoded_rows_train = []\n",
    "    for i in range(len(X_tr_aug_df)):\n",
    "        # The decode_row function finds the max value (closest to 1) in the unscaled array\n",
    "        decoded_record = decode_row(X_tr_aug_df.iloc[i], dummy_map)\n",
    "        decoded_record[\"COPD\"] = int(y_tr_aug_series.iloc[i])\n",
    "        decoded_rows_train.append(decoded_record)\n",
    "    decoded_train_df = pd.DataFrame(decoded_rows_train)\n",
    "\n",
    "    # 3) Decode the test set (Test was never oversampled, so use the original one-hot X_te_full)\n",
    "    decoded_rows_test = []\n",
    "    for i in range(len(X_te_full)):\n",
    "        decoded_record = decode_row(X_te_full.iloc[i], dummy_map)\n",
    "        decoded_record[\"COPD\"] = int(y_te_full.iloc[i])\n",
    "        decoded_rows_test.append(decoded_record)\n",
    "    decoded_test_df = pd.DataFrame(decoded_rows_test)\n",
    "\n",
    "    # 4) Store data in dicts and save to files\n",
    "    adasyn_train_decoded[fold_id] = decoded_train_df\n",
    "    adasyn_test_decoded[fold_id]  = decoded_test_df\n",
    "\n",
    "    output_dir = \"/Users/hwangsia/\"\n",
    "    # Save files using na_rep='NA' for consistent representation of missing values\n",
    "    decoded_train_df.to_csv(f\"{output_dir}adasyn_train_fold{fold_id}.csv\",\n",
    "                            index=False, na_rep='NA')\n",
    "    decoded_test_df.to_csv(f\"{output_dir}adasyn_test_fold{fold_id}.csv\",\n",
    "                        index=False, na_rep='NA')\n",
    "\n",
    "    # Save grid search results if available\n",
    "    if not grid_df.empty:\n",
    "        grid_df_sorted.to_csv(f\"{output_dir}adasyn_grid_fold{fold_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f0e35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== per-fold raw results =====\n",
      "   fold  adasyn_r  adasyn_k  orig_recall  orig_precision   orig_f1  orig_auc  \\\n",
      "0     1       1.0        13     0.014493        0.500000  0.028169  0.750484   \n",
      "1     2       1.0         7     0.014706        0.500000  0.028571  0.734388   \n",
      "2     3       1.0         3     0.058824        0.444444  0.103896  0.708011   \n",
      "3     4       1.0         3     0.014706        0.333333  0.028169  0.676395   \n",
      "4     5       1.0         7     0.043478        1.000000  0.083333  0.751700   \n",
      "5     1       1.0        13     0.014493        0.500000  0.028169  0.750484   \n",
      "6     2       1.0         7     0.014706        0.500000  0.028571  0.734388   \n",
      "7     3       1.0         3     0.058824        0.444444  0.103896  0.708011   \n",
      "8     4       1.0         3     0.014706        0.333333  0.028169  0.676395   \n",
      "9     5       1.0         7     0.043478        1.000000  0.083333  0.751700   \n",
      "\n",
      "   aug_recall  aug_precision    aug_f1   aug_auc  \n",
      "0    0.739130       0.217021  0.335526  0.729057  \n",
      "1    0.720588       0.221719  0.339100  0.732335  \n",
      "2    0.617647       0.207921  0.311111  0.705988  \n",
      "3    0.602941       0.193396  0.292857  0.668876  \n",
      "4    0.724638       0.234742  0.354610  0.757038  \n",
      "5    0.739130       0.217021  0.335526  0.729057  \n",
      "6    0.720588       0.221719  0.339100  0.732335  \n",
      "7    0.617647       0.207921  0.311111  0.705988  \n",
      "8    0.602941       0.193396  0.292857  0.668876  \n",
      "9    0.724638       0.234742  0.354610  0.757038  \n",
      "\n",
      "===== summary across all 5 folds =====\n",
      "   orig_recall_mean  orig_recall_std  orig_f1_mean  orig_f1_std  \\\n",
      "0          0.029241         0.019538      0.054428     0.034417   \n",
      "\n",
      "   orig_auc_mean  orig_auc_std  aug_recall_mean  aug_recall_std  aug_f1_mean  \\\n",
      "0       0.724196      0.030178         0.680989        0.061387     0.326641   \n",
      "\n",
      "   aug_f1_std  aug_auc_mean  aug_auc_std  \n",
      "0    0.023089      0.718659     0.031294  \n",
      "\n",
      "Done: All results saved to /Users/hwangsia/\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 3. Final Results Summary (Mean/Std across all folds)\n",
    "# ------------------------------------------------\n",
    "\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(\"\\n===== per-fold raw results =====\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate mean and std (ddof=1 for sample std)\n",
    "summary = {\n",
    "    \"orig_recall_mean\":   results_df[\"orig_recall\"].mean(),\n",
    "    \"orig_recall_std\":    results_df[\"orig_recall\"].std(ddof=1),\n",
    "    \"orig_f1_mean\":       results_df[\"orig_f1\"].mean(),\n",
    "    \"orig_f1_std\":        results_df[\"orig_f1\"].std(ddof=1),\n",
    "    \"orig_auc_mean\":      results_df[\"orig_auc\"].mean(),\n",
    "    \"orig_auc_std\":       results_df[\"orig_auc\"].std(ddof=1),\n",
    "\n",
    "    \"aug_recall_mean\":    results_df[\"aug_recall\"].mean(),\n",
    "    \"aug_recall_std\":     results_df[\"aug_recall\"].std(ddof=1),\n",
    "    \"aug_f1_mean\":        results_df[\"aug_f1\"].mean(),\n",
    "    \"aug_f1_std\":         results_df[\"aug_f1\"].std(ddof=1),\n",
    "    \"aug_auc_mean\":       results_df[\"aug_auc\"].mean(),\n",
    "    \"aug_auc_std\":        results_df[\"aug_auc\"].std(ddof=1),\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "print(\"\\n===== summary across all 5 folds =====\")\n",
    "print(summary_df)\n",
    "\n",
    "# Save final summaries\n",
    "results_df.to_csv(f\"{output_dir}fold_results_5fold.csv\", index=False)\n",
    "summary_df.to_csv(f\"{output_dir}fold_summary_5fold.csv\", index=False)\n",
    "\n",
    "print(f\"\\nDone: All results saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
